{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7cafa33-bed2-4407-87f5-51d133cec1df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/4TB/TCGA_Colorectal/scripts/3-processing'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055d1b4c-1d1d-40f9-8c0e-070ee4143634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from guppy import hpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92550cc0-9de0-4e4d-b8ef-f5f66b82daba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "starting parse\n",
      "Partition of a set of 10051814 objects. Total size = 6799517450 bytes.\n",
      " Index  Count   %     Size   % Cumulative  % Kind (class / dict of class)\n",
      "     0      2   0 4653608366  68 4653608366  68 pandas.core.frame.DataFrame\n",
      "     1 8759854  87 832345323  12 5485953689  81 str\n",
      "     2     78   0 630723278   9 6116676967  90 numpy.ndarray\n",
      "     3 963213  10 627823800   9 6744500767  99 dict (no owner)\n",
      "     4   4709   0 16610632   0 6761111399  99 list\n",
      "     5 130839   1 11049224   0 6772160623 100 tuple\n",
      "     6  57343   1  4414002   0 6776574625 100 bytes\n",
      "     7  29041   0  4202992   0 6780777617 100 types.CodeType\n",
      "     8  26580   0  3827520   0 6784605137 100 function\n",
      "     9   3553   0  3336248   0 6787941385 100 type\n",
      "<1228 more rows. Type e.g. '_.more' to view.>\n",
      "finished parse\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "import sys, os\n",
    "from os.path import join as pj\n",
    "import pandas as pd\n",
    "\n",
    "# ====== PROJECT SCAFFOLD ======\n",
    "# Arguments passed into script by Docker command\n",
    "project = sys.argv[1]\n",
    "file_id = sys.argv[2]\n",
    "\n",
    "# Mounted volume\n",
    "wd  = \"/mnt/4TB/TCGA_Colorectal/scripts/3-processing\"\n",
    "boop = pj(wd, '43cbb4c9-4dc8-4e7a-ac69-779f5a76dced.vep')\n",
    "\n",
    "# ====== START PROCESSING ======\n",
    "print('starting parse')\n",
    "# Load our vep-annotated vcf file\n",
    "with open(boop) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract VEP the schema above from file header\n",
    "prefix_schema = \"Ensembl VEP. Format: \"\n",
    "for line in lines:\n",
    "    if (prefix_schema in line):              \n",
    "        # We want everything after format and before closing syntax – broken into list\n",
    "        vep_cols = line.split(prefix_schema)[1].split('\">')[0].split('|')\n",
    "        vep_cols = [f\"VEP_{c}\" for c in vep_cols]\n",
    "        break\n",
    "\n",
    "# Where file header ends and real data begins\n",
    "prefix_cols = \"#CHROM\"\n",
    "header_lineNum = None\n",
    "for i, line in enumerate(lines):\n",
    "    if (line.startswith(prefix_cols)): \n",
    "        # Pandas wants line number - 1 so don't worry about zero-based index\n",
    "        header_lineNum = i\n",
    "        break\n",
    "if (header_lineNum==None):\n",
    "    msg = 'Error - VEP did not write data to VCF\\nPlease verify you downloaded the indexed version of VEP cache.\\nAnd that the VCF file name you are trying to create does not exist already.'\n",
    "    raise Exception(msg)\n",
    "        \n",
    "# Read vcf into a dataframe\n",
    "df_vcf = pd.read_csv(boop, sep='\\t', header=header_lineNum)\n",
    "df_vcf.rename(columns={'#CHROM':'CHROM'}, inplace=True)\n",
    "\n",
    "# Everything before `;CSQ=` becomes INFO col / after becomes VEP col\n",
    "df_vcf[['INFO', 'VEP']] = df_vcf['INFO'].str.split(';CSQ=', n=1, expand=True)\n",
    "\n",
    "# Explode the new VEP col\n",
    "df_vcf[vep_cols] = df_vcf['VEP'].str.split('|',expand=True)\n",
    "df_vcf = df_vcf.drop(columns=['VEP'])\n",
    "\n",
    "\"\"\"\n",
    "Tabular VCF FORMAT Fields\n",
    "All of my variants were using the same format fields.\n",
    "\"\"\"\n",
    "# Check that format is the same for all variants\n",
    "if (len(set(df_vcf['FORMAT'])) == 1):\n",
    "    # Break the format keys into a list\n",
    "    format_cols = df_vcf['FORMAT'][0].split(':')\n",
    "    format_cols = [f\"FORMAT_{c}\" for c in format_cols]\n",
    "\n",
    "    # Need to find the case-specific column that is paired with FORMAT \n",
    "    # e.g. column named TCGA-F4-6459-10A-01D-1771-10\n",
    "    vcf_cols   = df_vcf.columns.tolist()\n",
    "    format_idx = [i for i, col in enumerate(vcf_cols) if 'FORMAT'==col][0]\n",
    "    case_idx   = format_idx + 1\n",
    "    case_col   = vcf_cols[case_idx] \n",
    "\n",
    "    # Explode the formatted sample-specific data \n",
    "    df_vcf[format_cols] = df_vcf[case_col].str.split(':',expand=True)\n",
    "    df_vcf = df_vcf.drop(columns=[case_col, 'FORMAT'])\n",
    "else:\n",
    "    print(\"Warning – FORMAT could not be exploded as format not the same for all variants\")\n",
    "\n",
    "\"\"\"\n",
    "Tabular VCF INFO Fields\n",
    "Remember, at this point, the VEP fields are no longer in the VEP INFO column.\n",
    "This handles sparsity; some of my variants didn't have all of the INFO fields\n",
    "\"\"\"\n",
    "# Sparsity means parsing rows individually\n",
    "info_entries = []\n",
    "for row in df_vcf['INFO']: \n",
    "    # Break the info string into key-value pairs\n",
    "    row_pairs = dict(item.split(\"=\") for item in row.split(\";\"))\n",
    "    info_entries.append(row_pairs)\n",
    "\n",
    "# Easy to make df from dict, but doing so makes separate df\n",
    "df_info = pd.DataFrame.from_dict(info_entries)\n",
    "\n",
    "# Explode the info column\n",
    "info_cols = df_info.columns.tolist()\n",
    "info_colsRename = [f\"INFO_{c}\" for c in info_cols]\n",
    "renames = dict(zip(info_cols, info_colsRename))\n",
    "df_info = df_info.rename(columns=renames)\n",
    "\n",
    "# Merge back with the main df\n",
    "df_vcf = pd.concat([df_vcf, df_info], axis=1)\n",
    "df_vcf = df_vcf.drop(columns=['INFO'])\n",
    "\n",
    "h = hpy()\n",
    "print(h.heap())\n",
    "del df_info\n",
    "print('finished parse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a9bc1d-4e8d-4944-ae90-8c3a6e712b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "# Save it\n",
    "beep = pj(wd, '43cbb4c9-4dc8-4e7a-ac69-779f5a76dced.pq')\n",
    "df_vcf.to_parquet(beep)\n",
    "print(\"end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
